{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12a113f7-0629-4c67-8d16-d87ee876d437",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¸°ì¡´ í™˜ê²½ ë³€ìˆ˜ì˜ API í‚¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "================================================================================\n",
      "7.3.5 ì»¤ìŠ¤í…€ ì²´ì¸ (Custom Chain)\n",
      "================================================================================\n",
      "\n",
      "ì›ì„œ ì½”ë“œì˜ ë¬¸ì œì :\n",
      "1. Chain í´ë˜ìŠ¤ì™€ LLMChainì´ deprecatedë¨\n",
      "2. run() ë©”ì„œë“œê°€ deprecatedë¨\n",
      "\n",
      "ìˆ˜ì • ë‚´ìš©:\n",
      "- Chain í´ë˜ìŠ¤ â†’ RunnableSequenceì™€ ì»¤ìŠ¤í…€ í•¨ìˆ˜ ì¡°í•©\n",
      "- LLMChain â†’ prompt | llm ë°©ì‹\n",
      "- run() â†’ invoke() ë©”ì„œë“œ\n",
      "\n",
      "ìƒˆë¡œìš´ ì ‘ê·¼ë²•:\n",
      "- RunnableLambdaë¥¼ ì‚¬ìš©í•œ ì»¤ìŠ¤í…€ ë¡œì§\n",
      "- í•¨ìˆ˜í˜• ì²´ì¸ êµ¬ì„±\n",
      "- | ì—°ì‚°ìë¥¼ í™œìš©í•œ ì²´ì¸ ì—°ê²°\n",
      "\n",
      "\n",
      "============================================================\n",
      "ë°©ë²• 1: RunnableLambdaë¥¼ ì‚¬ìš©í•œ í˜„ëŒ€ì  ì»¤ìŠ¤í…€ ì²´ì¸\n",
      "============================================================\n",
      "í…ŒìŠ¤íŠ¸ ë‹¨ì–´: 'artificial'\n",
      "\n",
      "ì—°ê²°ëœ ì¶œë ¥:\n",
      "ì •ì˜: The word 'artificial' refers to something that is made or produced by human beings rather than occurring naturally. It can also refer to something that is not genuine or authentic.\n",
      "\n",
      "ë™ì˜ì–´: synthetic\n",
      "\n",
      "============================================================\n",
      "ë°©ë²• 2: ë‹¤ë‹¨ê³„ ë¶„ì„ ì»¤ìŠ¤í…€ ì²´ì¸\n",
      "============================================================\n",
      "ë‹¤ë‹¨ê³„ ë¶„ì„ í…ŒìŠ¤íŠ¸: 'intelligence'\n",
      "\n",
      "ë‹¤ê°ë„ ë¶„ì„ ê²°ê³¼:\n",
      "ë‹¨ì–´ ë¶„ì„: intelligence\n",
      "\n",
      "ğŸ“– ì •ì˜: Intelligence is the ability to learn, understand, and solve problems. It involves being able to think critically, make decisions, and adapt to new situations.\n",
      "\n",
      "ğŸŒ ì–´ì›: The word \"intelligence\" comes from the Latin word \"intelligentia,\" which is derived from the verb \"intelligere,\" meaning \"to understand\" or \"to comprehend.\" The prefix \"inter-\" means \"between\" or \"among,\" and the root \"legere\" means \"to choose\" or \"to gather.\" So, the original meaning of \"intelligence\" was the ability to choose or gather information between or among different sources.\n",
      "\n",
      "ğŸ“ ì‚¬ìš© ì˜ˆì‹œ: His intelligence allowed him to solve the complex problem in record time.\n",
      "\n",
      "ğŸ”„ ë™ì˜ì–´: 1. intellect\n",
      "2. cleverness\n",
      "3. wisdom\n",
      "\n",
      "============================================================\n",
      "ë°©ë²• 3: ì¡°ê±´ë¶€ ë¡œì§ì´ ìˆëŠ” ìŠ¤ë§ˆíŠ¸ ì²´ì¸\n",
      "============================================================\n",
      "ë‹¤ì–‘í•œ ê¸¸ì´ì˜ ë‹¨ì–´ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸:\n",
      "\n",
      "í…ŒìŠ¤íŠ¸ ë‹¨ì–´: 'AI'\n",
      "ì²˜ë¦¬ ë°©ì‹: ê°„ë‹¨ ì •ì˜\n",
      "ë‹¨ì–´ ê¸¸ì´: 2ì\n",
      "\n",
      "ê²°ê³¼:\n",
      "AI, or artificial intelligence, refers to the simulation of human intelligence processes by machines, especially computer systems.\n",
      "--------------------------------------------------\n",
      "\n",
      "í…ŒìŠ¤íŠ¸ ë‹¨ì–´: 'computer'\n",
      "ì²˜ë¦¬ ë°©ì‹: ì •ì˜ + ì˜ˆì‹œ\n",
      "ë‹¨ì–´ ê¸¸ì´: 8ì\n",
      "\n",
      "ê²°ê³¼:\n",
      "A computer is an electronic device that can store, retrieve, and process data.\n",
      "\n",
      "Example sentence: I use my computer to browse the internet and work on assignments.\n",
      "--------------------------------------------------\n",
      "\n",
      "í…ŒìŠ¤íŠ¸ ë‹¨ì–´: 'artificial'\n",
      "ì²˜ë¦¬ ë°©ì‹: ìƒì„¸ ë¶„ì„\n",
      "ë‹¨ì–´ ê¸¸ì´: 10ì\n",
      "\n",
      "ê²°ê³¼:\n",
      "The term \"artificial\" is derived from the Latin word \"artificium,\" which means \"skill\" or \"craftsmanship.\" It is used to describe something that is made or produced by human beings, rather than occurring naturally. \n",
      "\n",
      "In general, artificial things are created through human intervention and manipulation, often using technology or other tools. This can include artificial intelligence, artificial flavors, artificial materials, and artificial light, among many other examples. \n",
      "\n",
      "The concept of artificiality is often contrasted with the idea of naturalness, with artificial things being seen as separate from or in opposition to the natural world. However, it is important to note that artificial things can still have value and serve important purposes in human society. \n",
      "\n",
      "In the context of art, the term \"artificial\" can refer to artwork that is intentionally created in a way that emphasizes its artificiality, such as through the use of synthetic materials or digital techniques. This can be a way for artists to explore the boundaries between the natural and the artificial, and to challenge traditional notions of beauty and authenticity. \n",
      "\n",
      "Overall, the term \"artificial\" is a versatile and complex concept that is used in a variety of contexts to describe things that are created or manipulated by human beings.\n",
      "--------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "ë°©ë²• 4: ì²´ì¸ë“¤ì˜ ì²´ì¸ - ë³µí•© ì›Œí¬í”Œë¡œìš°\n",
      "============================================================\n",
      "ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸: 'robot'\n",
      "\n",
      "ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê²°ê³¼:\n",
      "ì›Œí¬í”Œë¡œìš° ê²°ê³¼:\n",
      "\n",
      "1ï¸âƒ£ ë‹¨ì–´: robot\n",
      "2ï¸âƒ£ ì •ì˜: A robot is a machine capable of carrying out complex actions automatically, often controlled by a computer program.\n",
      "3ï¸âƒ£ ì¹´í…Œê³ ë¦¬: The word 'robot' belongs to the category of technology.\n",
      "4ï¸âƒ£ ê´€ë ¨ ë‹¨ì–´: 1. Automation\n",
      "2. Artificial intelligence\n",
      "3. Robotics\n",
      "\n",
      "============================================================\n",
      "ì›ì„œ ë°©ì‹ vs ìƒˆë¡œìš´ ë°©ì‹ ë¹„êµ\n",
      "============================================================\n",
      "\n",
      "ì›ì„œ ì½”ë“œ (Deprecated):\n",
      "from langchain.chains.base import Chain\n",
      "\n",
      "class ConcatenateChain(Chain):\n",
      "    chain_1: LLMChain\n",
      "    chain_2: LLMChain\n",
      "    \n",
      "    def _call(self, inputs):\n",
      "        output1 = self.chain_1.run(inputs)    # âš ï¸ Deprecated\n",
      "        output2 = self.chain_2.run(inputs)    # âš ï¸ Deprecated\n",
      "        return {\"concat_output\": output1 + output2}\n",
      "\n",
      "ìƒˆë¡œìš´ ë°©ì‹ (í˜„ì¬ ê¶Œì¥):\n",
      "from langchain_core.runnables import RunnableLambda\n",
      "\n",
      "def concatenate_outputs(inputs):\n",
      "    output1 = chain1.invoke(inputs)           # âœ… ê¶Œì¥\n",
      "    output2 = chain2.invoke(inputs)           # âœ… ê¶Œì¥\n",
      "    return {\"concat_output\": output1.content + output2.content}\n",
      "\n",
      "custom_chain = RunnableLambda(concatenate_outputs)\n",
      "\n",
      "\n",
      "============================================================\n",
      "ì»¤ìŠ¤í…€ ì²´ì¸ í™œìš© íŒ\n",
      "============================================================\n",
      "\n",
      "ì»¤ìŠ¤í…€ ì²´ì¸ ì„¤ê³„ ì›ì¹™:\n",
      "\n",
      "1. ë‹¨ìˆœí•¨ ìœ ì§€:\n",
      "   - ë³µì¡í•œ ë¡œì§ì€ ì—¬ëŸ¬ ê°œì˜ ì‘ì€ í•¨ìˆ˜ë¡œ ë¶„í• \n",
      "   - ê° í•¨ìˆ˜ëŠ” í•˜ë‚˜ì˜ ëª…í™•í•œ ì—­í•  ìˆ˜í–‰\n",
      "\n",
      "2. ì¬ì‚¬ìš©ì„±:\n",
      "   - ê³µí†µ ë¡œì§ì€ ë³„ë„ í•¨ìˆ˜ë¡œ ë¶„ë¦¬\n",
      "   - ë§¤ê°œë³€ìˆ˜ë¥¼ í†µí•œ ìœ ì—°í•œ ì„¤ì •\n",
      "\n",
      "3. ì˜¤ë¥˜ ì²˜ë¦¬:\n",
      "   - try-except ë¸”ë¡ìœ¼ë¡œ ì˜ˆì™¸ ìƒí™© ëŒ€ë¹„\n",
      "   - ì˜ë¯¸ ìˆëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€ ì œê³µ\n",
      "\n",
      "4. í…ŒìŠ¤íŠ¸ ê°€ëŠ¥ì„±:\n",
      "   - ê° ë‹¨ê³„ë³„ë¡œ ë…ë¦½ì  í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ê³„\n",
      "   - ì…ë ¥/ì¶œë ¥ í˜•ì‹ í‘œì¤€í™”\n",
      "\n",
      "5. ì„±ëŠ¥ ìµœì í™”:\n",
      "   - ë¶ˆí•„ìš”í•œ API í˜¸ì¶œ ìµœì†Œí™”\n",
      "   - ê²°ê³¼ ìºì‹± ê³ ë ¤\n",
      "\n",
      "ì‹¤ì œ í™œìš© ì‚¬ë¡€:\n",
      "- ë‹¤êµ­ì–´ ë²ˆì—­ íŒŒì´í”„ë¼ì¸\n",
      "- ë¬¸ì„œ ìš”ì•½ ë° ë¶„ì„ ì‹œìŠ¤í…œ\n",
      "- ê³ ê° ì„œë¹„ìŠ¤ ì‘ë‹µ ìƒì„±ê¸°\n",
      "- ì°½ì˜ì  ì½˜í…ì¸  ì œì‘ ë„êµ¬\n",
      "- ë°ì´í„° ë¶„ì„ ë° ë³´ê³ ì„œ ìƒì„±\n",
      "\n",
      "\n",
      "ğŸ‰ 7.3.5 ì»¤ìŠ¤í…€ ì²´ì¸ ì˜ˆì œ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# 7.3.5 - ì»¤ìŠ¤í…€ ì²´ì¸ (Custom Chain)\n",
    "# LangChainì˜ ê¸°ë³¸ ì²´ì¸ìœ¼ë¡œ í•´ê²°ë˜ì§€ ì•ŠëŠ” íŠ¹ì • ì‘ì—…ì„ ìœ„í•œ ì‚¬ìš©ì ì •ì˜ ì²´ì¸ ë§Œë“¤ê¸°\n",
    "\n",
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "# !pip install -U langchain==0.2.17 langchain-openai langchain-core\n",
    "\n",
    "# =============================================================================\n",
    "# API í‚¤ ì„¤ì • (ë…ììš©)\n",
    "# =============================================================================\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "if 'OPENAI_API_KEY' not in os.environ:\n",
    "    api_key = getpass.getpass(\"OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”: \")\n",
    "    if api_key:\n",
    "        os.environ['OPENAI_API_KEY'] = api_key\n",
    "        print(\"API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(\"ê¸°ì¡´ í™˜ê²½ ë³€ìˆ˜ì˜ API í‚¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"7.3.5 ì»¤ìŠ¤í…€ ì²´ì¸ (Custom Chain)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "ì›ì„œ ì½”ë“œì˜ ë¬¸ì œì :\n",
    "1. Chain í´ë˜ìŠ¤ì™€ LLMChainì´ deprecatedë¨\n",
    "2. run() ë©”ì„œë“œê°€ deprecatedë¨\n",
    "\n",
    "ìˆ˜ì • ë‚´ìš©:\n",
    "- Chain í´ë˜ìŠ¤ â†’ RunnableSequenceì™€ ì»¤ìŠ¤í…€ í•¨ìˆ˜ ì¡°í•©\n",
    "- LLMChain â†’ prompt | llm ë°©ì‹\n",
    "- run() â†’ invoke() ë©”ì„œë“œ\n",
    "\n",
    "ìƒˆë¡œìš´ ì ‘ê·¼ë²•:\n",
    "- RunnableLambdaë¥¼ ì‚¬ìš©í•œ ì»¤ìŠ¤í…€ ë¡œì§\n",
    "- í•¨ìˆ˜í˜• ì²´ì¸ êµ¬ì„±\n",
    "- | ì—°ì‚°ìë¥¼ í™œìš©í•œ ì²´ì¸ ì—°ê²°\n",
    "\"\"\")\n",
    "\n",
    "# =============================================================================\n",
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "# =============================================================================\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from typing import Dict, Any\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# =============================================================================\n",
    "# ë°©ë²• 1: RunnableLambdaë¥¼ ì‚¬ìš©í•œ ì»¤ìŠ¤í…€ ì²´ì¸ (ìµœì‹  ë°©ì‹)\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ë°©ë²• 1: RunnableLambdaë¥¼ ì‚¬ìš©í•œ í˜„ëŒ€ì  ì»¤ìŠ¤í…€ ì²´ì¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "prompt1 = PromptTemplate.from_template(\"What is the meaning of the word '{word}'?\")\n",
    "prompt2 = PromptTemplate.from_template(\"Suggest a synonym for the word '{word}'.\")\n",
    "\n",
    "# ê°œë³„ ì²´ì¸ êµ¬ì„±\n",
    "chain1 = prompt1 | llm\n",
    "chain2 = prompt2 | llm\n",
    "\n",
    "# ì»¤ìŠ¤í…€ ì—°ê²° í•¨ìˆ˜\n",
    "def concatenate_outputs(inputs: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"ë‘ ì²´ì¸ì˜ ì¶œë ¥ì„ ì—°ê²°í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    word = inputs[\"word\"]\n",
    "    \n",
    "    # ê° ì²´ì¸ ì‹¤í–‰\n",
    "    output1 = chain1.invoke({\"word\": word})\n",
    "    output2 = chain2.invoke({\"word\": word})\n",
    "    \n",
    "    # ê²°ê³¼ ì—°ê²°\n",
    "    concatenated = f\"ì •ì˜: {output1.content.strip()}\\n\\në™ì˜ì–´: {output2.content.strip()}\"\n",
    "    \n",
    "    return {\"concat_output\": concatenated}\n",
    "\n",
    "# RunnableLambdaë¡œ ì»¤ìŠ¤í…€ ì²´ì¸ ìƒì„±\n",
    "modern_concat_chain = RunnableLambda(concatenate_outputs)\n",
    "\n",
    "print(\"í…ŒìŠ¤íŠ¸ ë‹¨ì–´: 'artificial'\")\n",
    "\n",
    "try:\n",
    "    result = modern_concat_chain.invoke({\"word\": \"artificial\"})\n",
    "    print(\"\\nì—°ê²°ëœ ì¶œë ¥:\")\n",
    "    print(result[\"concat_output\"])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# ë°©ë²• 2: ë” ë³µì¡í•œ ì»¤ìŠ¤í…€ ì²´ì¸ ì˜ˆì œ\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ë°©ë²• 2: ë‹¤ë‹¨ê³„ ë¶„ì„ ì»¤ìŠ¤í…€ ì²´ì¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ì—¬ëŸ¬ ë‹¨ê³„ì˜ ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ì»¤ìŠ¤í…€ ì²´ì¸\n",
    "def multi_analysis_chain(inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"ë‹¨ì–´ì— ëŒ€í•œ ë‹¤ê°ë„ ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ì²´ì¸\"\"\"\n",
    "    word = inputs[\"word\"]\n",
    "    \n",
    "    # ê°ê°ì˜ ë¶„ì„ í”„ë¡¬í”„íŠ¸\n",
    "    prompts = {\n",
    "        \"definition\": PromptTemplate.from_template(\"Define the word '{word}' in simple terms.\"),\n",
    "        \"etymology\": PromptTemplate.from_template(\"What is the etymology of the word '{word}'?\"),\n",
    "        \"usage\": PromptTemplate.from_template(\"Give an example sentence using the word '{word}'.\"),\n",
    "        \"synonyms\": PromptTemplate.from_template(\"List 3 synonyms for the word '{word}'.\")\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # ê° ë¶„ì„ ì‹¤í–‰\n",
    "    for analysis_type, prompt in prompts.items():\n",
    "        chain = prompt | llm\n",
    "        response = chain.invoke({\"word\": word})\n",
    "        results[analysis_type] = response.content.strip()\n",
    "    \n",
    "    # ê²°ê³¼ ì •ë¦¬\n",
    "    formatted_output = f\"\"\"ë‹¨ì–´ ë¶„ì„: {word}\n",
    "\n",
    "ğŸ“– ì •ì˜: {results['definition']}\n",
    "\n",
    "ğŸŒ ì–´ì›: {results['etymology']}\n",
    "\n",
    "ğŸ“ ì‚¬ìš© ì˜ˆì‹œ: {results['usage']}\n",
    "\n",
    "ğŸ”„ ë™ì˜ì–´: {results['synonyms']}\"\"\"\n",
    "    \n",
    "    return {\"analysis\": formatted_output}\n",
    "\n",
    "# ë‹¤ë‹¨ê³„ ë¶„ì„ ì²´ì¸ ìƒì„±\n",
    "analysis_chain = RunnableLambda(multi_analysis_chain)\n",
    "\n",
    "print(\"ë‹¤ë‹¨ê³„ ë¶„ì„ í…ŒìŠ¤íŠ¸: 'intelligence'\")\n",
    "\n",
    "try:\n",
    "    analysis_result = analysis_chain.invoke({\"word\": \"intelligence\"})\n",
    "    print(\"\\në‹¤ê°ë„ ë¶„ì„ ê²°ê³¼:\")\n",
    "    print(analysis_result[\"analysis\"])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ë‹¤ë‹¨ê³„ ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# ë°©ë²• 3: ì¡°ê±´ë¶€ ë¡œì§ì´ ìˆëŠ” ì»¤ìŠ¤í…€ ì²´ì¸\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ë°©ë²• 3: ì¡°ê±´ë¶€ ë¡œì§ì´ ìˆëŠ” ìŠ¤ë§ˆíŠ¸ ì²´ì¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def smart_word_processor(inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"ì…ë ¥ ë‹¨ì–´ì˜ íŠ¹ì„±ì— ë”°ë¼ ë‹¤ë¥¸ ì²˜ë¦¬ë¥¼ í•˜ëŠ” ìŠ¤ë§ˆíŠ¸ ì²´ì¸\"\"\"\n",
    "    word = inputs[\"word\"]\n",
    "    word_length = len(word)\n",
    "    \n",
    "    if word_length <= 4:\n",
    "        # ì§§ì€ ë‹¨ì–´: ê°„ë‹¨í•œ ì •ì˜\n",
    "        prompt = PromptTemplate.from_template(\"Give a very brief definition of '{word}'.\")\n",
    "        approach = \"ê°„ë‹¨ ì •ì˜\"\n",
    "    elif word_length <= 8:\n",
    "        # ì¤‘ê°„ ê¸¸ì´: ì •ì˜ + ì˜ˆì‹œ\n",
    "        prompt = PromptTemplate.from_template(\"Define '{word}' and give one example sentence.\")\n",
    "        approach = \"ì •ì˜ + ì˜ˆì‹œ\"\n",
    "    else:\n",
    "        # ê¸´ ë‹¨ì–´: ìƒì„¸ ë¶„ì„\n",
    "        prompt = PromptTemplate.from_template(\"Provide a detailed explanation of '{word}' including its origin and usage.\")\n",
    "        approach = \"ìƒì„¸ ë¶„ì„\"\n",
    "    \n",
    "    # ì²´ì¸ ì‹¤í–‰\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"word\": word})\n",
    "    \n",
    "    result = f\"ì²˜ë¦¬ ë°©ì‹: {approach}\\në‹¨ì–´ ê¸¸ì´: {word_length}ì\\n\\nê²°ê³¼:\\n{response.content}\"\n",
    "    \n",
    "    return {\"smart_output\": result}\n",
    "\n",
    "# ìŠ¤ë§ˆíŠ¸ ì²˜ë¦¬ ì²´ì¸ ìƒì„±\n",
    "smart_chain = RunnableLambda(smart_word_processor)\n",
    "\n",
    "# ë‹¤ì–‘í•œ ê¸¸ì´ì˜ ë‹¨ì–´ë¡œ í…ŒìŠ¤íŠ¸\n",
    "test_words = [\"AI\", \"computer\", \"artificial\"]\n",
    "\n",
    "print(\"ë‹¤ì–‘í•œ ê¸¸ì´ì˜ ë‹¨ì–´ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸:\")\n",
    "\n",
    "try:\n",
    "    for word in test_words:\n",
    "        result = smart_chain.invoke({\"word\": word})\n",
    "        print(f\"\\ní…ŒìŠ¤íŠ¸ ë‹¨ì–´: '{word}'\")\n",
    "        print(result[\"smart_output\"])\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"ìŠ¤ë§ˆíŠ¸ ì²´ì¸ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# ë°©ë²• 4: ì²´ì¸ë“¤ì˜ ì²´ì¸ (ì²´ì¸ ì¡°í•©)\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ë°©ë²• 4: ì²´ì¸ë“¤ì˜ ì²´ì¸ - ë³µí•© ì›Œí¬í”Œë¡œìš°\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def workflow_chain(inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"ì—¬ëŸ¬ ì²´ì¸ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” ì›Œí¬í”Œë¡œìš°\"\"\"\n",
    "    word = inputs[\"word\"]\n",
    "    \n",
    "    # 1ë‹¨ê³„: ê¸°ë³¸ ì •ì˜\n",
    "    definition_prompt = PromptTemplate.from_template(\"Define '{word}' in one sentence.\")\n",
    "    definition_chain = definition_prompt | llm\n",
    "    definition = definition_chain.invoke({\"word\": word}).content.strip()\n",
    "    \n",
    "    # 2ë‹¨ê³„: ì •ì˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜\n",
    "    category_prompt = PromptTemplate.from_template(\n",
    "        \"Based on this definition: '{definition}', what category does the word '{word}' belong to? (e.g., technology, nature, emotion, etc.)\"\n",
    "    )\n",
    "    category_chain = category_prompt | llm\n",
    "    category = category_chain.invoke({\"word\": word, \"definition\": definition}).content.strip()\n",
    "    \n",
    "    # 3ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ì— ë§ëŠ” ê´€ë ¨ ë‹¨ì–´ ì œì•ˆ\n",
    "    related_prompt = PromptTemplate.from_template(\n",
    "        \"Suggest 3 words related to '{word}' in the '{category}' category.\"\n",
    "    )\n",
    "    related_chain = related_prompt | llm\n",
    "    related_words = related_chain.invoke({\"word\": word, \"category\": category}).content.strip()\n",
    "    \n",
    "    # ìµœì¢… ê²°ê³¼ êµ¬ì„±\n",
    "    workflow_result = f\"\"\"ì›Œí¬í”Œë¡œìš° ê²°ê³¼:\n",
    "\n",
    "1ï¸âƒ£ ë‹¨ì–´: {word}\n",
    "2ï¸âƒ£ ì •ì˜: {definition}\n",
    "3ï¸âƒ£ ì¹´í…Œê³ ë¦¬: {category}\n",
    "4ï¸âƒ£ ê´€ë ¨ ë‹¨ì–´: {related_words}\"\"\"\n",
    "    \n",
    "    return {\"workflow_output\": workflow_result}\n",
    "\n",
    "# ì›Œí¬í”Œë¡œìš° ì²´ì¸ ìƒì„±\n",
    "workflow = RunnableLambda(workflow_chain)\n",
    "\n",
    "print(\"ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸: 'robot'\")\n",
    "\n",
    "try:\n",
    "    workflow_result = workflow.invoke({\"word\": \"robot\"})\n",
    "    print(\"\\nì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê²°ê³¼:\")\n",
    "    print(workflow_result[\"workflow_output\"])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ì›Œí¬í”Œë¡œìš° ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# ì›ì„œ ë°©ì‹ê³¼ ë¹„êµ (ì°¸ê³ ìš©)\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ì›ì„œ ë°©ì‹ vs ìƒˆë¡œìš´ ë°©ì‹ ë¹„êµ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "ì›ì„œ ì½”ë“œ (Deprecated):\n",
    "from langchain.chains.base import Chain\n",
    "\n",
    "class ConcatenateChain(Chain):\n",
    "    chain_1: LLMChain\n",
    "    chain_2: LLMChain\n",
    "    \n",
    "    def _call(self, inputs):\n",
    "        output1 = self.chain_1.run(inputs)    # âš ï¸ Deprecated\n",
    "        output2 = self.chain_2.run(inputs)    # âš ï¸ Deprecated\n",
    "        return {\"concat_output\": output1 + output2}\n",
    "\n",
    "ìƒˆë¡œìš´ ë°©ì‹ (í˜„ì¬ ê¶Œì¥):\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def concatenate_outputs(inputs):\n",
    "    output1 = chain1.invoke(inputs)           # âœ… ê¶Œì¥\n",
    "    output2 = chain2.invoke(inputs)           # âœ… ê¶Œì¥\n",
    "    return {\"concat_output\": output1.content + output2.content}\n",
    "\n",
    "custom_chain = RunnableLambda(concatenate_outputs)\n",
    "\"\"\")\n",
    "\n",
    "# =============================================================================\n",
    "# í™œìš© íŒê³¼ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ì»¤ìŠ¤í…€ ì²´ì¸ í™œìš© íŒ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "ì»¤ìŠ¤í…€ ì²´ì¸ ì„¤ê³„ ì›ì¹™:\n",
    "\n",
    "1. ë‹¨ìˆœí•¨ ìœ ì§€:\n",
    "   - ë³µì¡í•œ ë¡œì§ì€ ì—¬ëŸ¬ ê°œì˜ ì‘ì€ í•¨ìˆ˜ë¡œ ë¶„í• \n",
    "   - ê° í•¨ìˆ˜ëŠ” í•˜ë‚˜ì˜ ëª…í™•í•œ ì—­í•  ìˆ˜í–‰\n",
    "\n",
    "2. ì¬ì‚¬ìš©ì„±:\n",
    "   - ê³µí†µ ë¡œì§ì€ ë³„ë„ í•¨ìˆ˜ë¡œ ë¶„ë¦¬\n",
    "   - ë§¤ê°œë³€ìˆ˜ë¥¼ í†µí•œ ìœ ì—°í•œ ì„¤ì •\n",
    "\n",
    "3. ì˜¤ë¥˜ ì²˜ë¦¬:\n",
    "   - try-except ë¸”ë¡ìœ¼ë¡œ ì˜ˆì™¸ ìƒí™© ëŒ€ë¹„\n",
    "   - ì˜ë¯¸ ìˆëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€ ì œê³µ\n",
    "\n",
    "4. í…ŒìŠ¤íŠ¸ ê°€ëŠ¥ì„±:\n",
    "   - ê° ë‹¨ê³„ë³„ë¡œ ë…ë¦½ì  í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ê³„\n",
    "   - ì…ë ¥/ì¶œë ¥ í˜•ì‹ í‘œì¤€í™”\n",
    "\n",
    "5. ì„±ëŠ¥ ìµœì í™”:\n",
    "   - ë¶ˆí•„ìš”í•œ API í˜¸ì¶œ ìµœì†Œí™”\n",
    "   - ê²°ê³¼ ìºì‹± ê³ ë ¤\n",
    "\n",
    "ì‹¤ì œ í™œìš© ì‚¬ë¡€:\n",
    "- ë‹¤êµ­ì–´ ë²ˆì—­ íŒŒì´í”„ë¼ì¸\n",
    "- ë¬¸ì„œ ìš”ì•½ ë° ë¶„ì„ ì‹œìŠ¤í…œ\n",
    "- ê³ ê° ì„œë¹„ìŠ¤ ì‘ë‹µ ìƒì„±ê¸°\n",
    "- ì°½ì˜ì  ì½˜í…ì¸  ì œì‘ ë„êµ¬\n",
    "- ë°ì´í„° ë¶„ì„ ë° ë³´ê³ ì„œ ìƒì„±\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nğŸ‰ 7.3.5 ì»¤ìŠ¤í…€ ì²´ì¸ ì˜ˆì œ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83088b44-8816-4dcf-85d7-859043c603cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "my_project_env",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "My Project (Python) (Local)",
   "language": "python",
   "name": "my_project_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
