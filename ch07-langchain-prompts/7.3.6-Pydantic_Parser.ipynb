{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a73a5fa-a64c-4da3-a4d9-50a8bc4529d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¸°ì¡´ í™˜ê²½ ë³€ìˆ˜ì˜ API í‚¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "======================================================================\n",
      "7.3.6 Pydantic ì¶œë ¥ íŒŒì„œ\n",
      "======================================================================\n",
      "\n",
      "Pydantic v2 ì£¼ìš” ë³€ê²½ì‚¬í•­:\n",
      "1. @validator â†’ @field_validatorë¡œ ë°ì½”ë ˆì´í„° ë³€ê²½\n",
      "2. í•¨ìˆ˜ ë§¤ê°œë³€ìˆ˜ëª… ë³€ê²½ (v â†’ ì‹¤ì œ í•„ë“œëª…)\n",
      "3. ë” ì—„ê²©í•œ íƒ€ì… ê²€ì¦\n",
      "4. ì„±ëŠ¥ í–¥ìƒ\n",
      "\n",
      "í•µì‹¬ ê°œë…:\n",
      "- êµ¬ì¡°í™”ëœ ì¶œë ¥ ë³´ì¥\n",
      "- ìë™ ë°ì´í„° ê²€ì¦\n",
      "- íƒ€ì… ì•ˆì „ì„± ì œê³µ\n",
      "- ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬\n",
      "\n",
      "\n",
      "============================================================\n",
      "ê¸°ë³¸ Pydantic ëª¨ë¸: ë‹¨ì–´ ì œì•ˆ\n",
      "============================================================\n",
      "ìƒì„±ëœ í˜•ì‹ ì§€ì‹œì‚¬í•­:\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"ë‹¨ì–´ ì œì•ˆì„ ìœ„í•œ Pydantic ëª¨ë¸\", \"properties\": {\"words\": {\"description\": \"ë§¥ë½ì— ë”°ë¥¸ ëŒ€ì²´ ë‹¨ì–´ë“¤ì˜ ë¦¬ìŠ¤íŠ¸\", \"items\": {\"type\": \"string\"}, \"title\": \"Words\", \"type\": \"array\"}}, \"required\": [\"words\"]}\n",
      "```\n",
      "\n",
      "í…ŒìŠ¤íŠ¸ ë‹¨ì–´ë“¤: ['artificial', 'intelligent', 'creative']\n",
      "\n",
      "ë‹¨ì–´: artificial\n",
      "ì œì•ˆëœ ë‹¨ì–´ë“¤: ['synthetic', 'man-made', 'imitation']\n",
      "ê²°ê³¼ íƒ€ì…: <class '__main__.Suggestions'>\n",
      "\n",
      "ë‹¨ì–´: intelligent\n",
      "ì œì•ˆëœ ë‹¨ì–´ë“¤: ['clever', 'smart', 'brainy']\n",
      "ê²°ê³¼ íƒ€ì…: <class '__main__.Suggestions'>\n",
      "\n",
      "ë‹¨ì–´: creative\n",
      "ì œì•ˆëœ ë‹¨ì–´ë“¤: ['innovative', 'imaginative', 'original']\n",
      "ê²°ê³¼ íƒ€ì…: <class '__main__.Suggestions'>\n",
      "\n",
      "============================================================\n",
      "ë³µí•© Pydantic ëª¨ë¸: ë‹¨ì–´ ë¶„ì„\n",
      "============================================================\n",
      "ë³µí•© ë¶„ì„ í…ŒìŠ¤íŠ¸: 'technology'\n",
      "\n",
      "=== ë‹¨ì–´ ë¶„ì„ ê²°ê³¼ ===\n",
      "ë‹¨ì–´: technology\n",
      "ì •ì˜: ê¸°ìˆ  ë˜ëŠ” ê¸°ìˆ ì ì¸ ì§€ì‹ì„ ê°€ë¦¬í‚¤ëŠ” ë‹¨ì–´\n",
      "í’ˆì‚¬: ëª…ì‚¬\n",
      "ë™ì˜ì–´: engineering, innovation, science\n",
      "ì˜ˆì‹œ ë¬¸ì¥: The rapid advancement of technology has greatly impacted our daily lives.\n",
      "ë‚œì´ë„: 5/10\n",
      "\n",
      "============================================================\n",
      "ì„ íƒì  í•„ë“œ ëª¨ë¸: ì œí’ˆ ë¦¬ë·° ë¶„ì„\n",
      "============================================================\n",
      "ë¦¬ë·° ë¶„ì„ í…ŒìŠ¤íŠ¸:\n",
      "ìƒ˜í”Œ ë¦¬ë·°: ì•„ì´í° 15ëŠ” ì •ë§ í›Œë¥­í•œ ìŠ¤ë§ˆíŠ¸í°ì…ë‹ˆë‹¤. \n",
      "ì¹´ë©”ë¼ í’ˆì§ˆì´ ì´ì „ ëª¨ë¸ë³´ë‹¤ í›¨ì”¬ ì¢‹ì•„ì¡Œê³ , \n",
      "ë°°í„°ë¦¬ ìˆ˜ëª…ë„ ë§Œì¡±ìŠ¤ëŸ½ìŠµë‹ˆë‹¤. \n",
      "ë‹¤ë§Œ ê°€ê²©ì´ ì¢€ ë¹„ì‹¸ê¸´ í•˜ì§€ë§Œ ê·¸ë§Œí•œ ê°’ì–´ì¹˜ëŠ” í•˜ëŠ” ê²ƒ ê°™ì•„ìš”.\n",
      "ì „ë°˜ì ìœ¼ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤!\n",
      "\n",
      "=== ë¦¬ë·° ë¶„ì„ ê²°ê³¼ ===\n",
      "ì œí’ˆëª…: ì•„ì´í° 15\n",
      "í‰ì : 5/5\n",
      "ê°ì •: ê¸ì •\n",
      "ì£¼ìš” í¬ì¸íŠ¸:\n",
      "  1. ì¹´ë©”ë¼ í’ˆì§ˆì´ í–¥ìƒë¨\n",
      "  2. ë°°í„°ë¦¬ ìˆ˜ëª…ì´ ë§Œì¡±ìŠ¤ëŸ¬ì›€\n",
      "  3. ê°€ê²© ëŒ€ë¹„ ê°’ì–´ì¹˜ê°€ ì¢‹ìŒ\n",
      "ì¶”ì²œ: ì¶”ì²œí•©ë‹ˆë‹¤!\n",
      "\n",
      "============================================================\n",
      "ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„\n",
      "============================================================\n",
      "ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸:\n",
      "âœ… ì‹œë„ 1íšŒ ì„±ê³µ\n",
      "ìµœì¢… ê²°ê³¼: ['laptop', 'desktop', 'device']\n",
      "\n",
      "============================================================\n",
      "Pydantic ì¶œë ¥ íŒŒì„œ í™œìš© íŒ\n",
      "============================================================\n",
      "\n",
      "Pydantic v2 ì£¼ìš” ê°œì„ ì‚¬í•­:\n",
      "1. @field_validator: ë” ëª…í™•í•œ ê²€ì¦ ë¡œì§\n",
      "2. íƒ€ì… íŒíŠ¸ ê°•í™”: ë” ì •í™•í•œ íƒ€ì… ì²´í‚¹\n",
      "3. ì„±ëŠ¥ í–¥ìƒ: ë” ë¹ ë¥¸ ê²€ì¦ ì†ë„\n",
      "4. ì—ëŸ¬ ë©”ì‹œì§€ ê°œì„ : ë” ëª…í™•í•œ ì˜¤ë¥˜ ì •ë³´\n",
      "\n",
      "ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤:\n",
      "1. í•„ë“œ ì„¤ëª… ìƒì„¸íˆ ì‘ì„± (description)\n",
      "2. ì ì ˆí•œ ì œì•½ì¡°ê±´ ì„¤ì • (ge, le, max_length ë“±)\n",
      "3. ì»¤ìŠ¤í…€ ê²€ì¦ ë¡œì§ í™œìš© (@field_validator)\n",
      "4. ì„ íƒì  í•„ë“œ ì ì ˆíˆ í™œìš© (Optional)\n",
      "5. ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§ êµ¬í˜„\n",
      "\n",
      "ì‹¤ì œ í™œìš© ì‚¬ë¡€:\n",
      "- API ì‘ë‹µ êµ¬ì¡°í™”\n",
      "- ë°ì´í„° ì¶”ì¶œ ë° ì •ì œ\n",
      "- ìë™ ê²€ì¦ ë° í’ˆì§ˆ ê´€ë¦¬\n",
      "- êµ¬ì¡°í™”ëœ ë³´ê³ ì„œ ìƒì„±\n",
      "- ë‹¤êµ­ì–´ ë²ˆì—­ ê²°ê³¼ í¬ë§·íŒ…\n",
      "\n",
      "\n",
      "ğŸ‰ 7.3.6 Pydantic ì¶œë ¥ íŒŒì„œ ì˜ˆì œ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# 7.3.6 - Pydantic ì¶œë ¥ íŒŒì„œ (Output Parser)\n",
    "# êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ìœ„í•œ Pydantic ëª¨ë¸ê³¼ ê²€ì¦ ê¸°ëŠ¥ í™œìš©\n",
    "\n",
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "# !pip install langchain==0.2.17 langchain-openai pydantic\n",
    "\n",
    "# =============================================================================\n",
    "# API í‚¤ ì„¤ì • (ë…ììš©)\n",
    "# =============================================================================\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "if 'OPENAI_API_KEY' not in os.environ:\n",
    "    api_key = getpass.getpass(\"OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”: \")\n",
    "    if api_key:\n",
    "        os.environ['OPENAI_API_KEY'] = api_key\n",
    "        print(\"API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(\"ê¸°ì¡´ í™˜ê²½ ë³€ìˆ˜ì˜ API í‚¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"7.3.6 Pydantic ì¶œë ¥ íŒŒì„œ\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "Pydantic v2 ì£¼ìš” ë³€ê²½ì‚¬í•­:\n",
    "1. @validator â†’ @field_validatorë¡œ ë°ì½”ë ˆì´í„° ë³€ê²½\n",
    "2. í•¨ìˆ˜ ë§¤ê°œë³€ìˆ˜ëª… ë³€ê²½ (v â†’ ì‹¤ì œ í•„ë“œëª…)\n",
    "3. ë” ì—„ê²©í•œ íƒ€ì… ê²€ì¦\n",
    "4. ì„±ëŠ¥ í–¥ìƒ\n",
    "\n",
    "í•µì‹¬ ê°œë…:\n",
    "- êµ¬ì¡°í™”ëœ ì¶œë ¥ ë³´ì¥\n",
    "- ìë™ ë°ì´í„° ê²€ì¦\n",
    "- íƒ€ì… ì•ˆì „ì„± ì œê³µ\n",
    "- ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬\n",
    "\"\"\")\n",
    "\n",
    "# =============================================================================\n",
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "# =============================================================================\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from typing import List, Optional\n",
    "import json\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# =============================================================================\n",
    "# ê¸°ë³¸ Pydantic ëª¨ë¸ ì •ì˜ (Pydantic v2 ê¸°ì¤€)\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ê¸°ë³¸ Pydantic ëª¨ë¸: ë‹¨ì–´ ì œì•ˆ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "class Suggestions(BaseModel):\n",
    "    \"\"\"ë‹¨ì–´ ì œì•ˆì„ ìœ„í•œ Pydantic ëª¨ë¸\"\"\"\n",
    "    words: List[str] = Field(description=\"ë§¥ë½ì— ë”°ë¥¸ ëŒ€ì²´ ë‹¨ì–´ë“¤ì˜ ë¦¬ìŠ¤íŠ¸\")\n",
    "    \n",
    "    @field_validator(\"words\")\n",
    "    @classmethod\n",
    "    def not_start_with_number(cls, words):\n",
    "        \"\"\"ë‹¨ì–´ê°€ ìˆ«ìë¡œ ì‹œì‘í•˜ì§€ ì•ŠëŠ”ì§€ ê²€ì¦\"\"\"\n",
    "        for item in words:\n",
    "            if item and item[0].isnumeric():\n",
    "                raise ValueError(\"ë‹¨ì–´ëŠ” ìˆ«ìë¡œ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        return words\n",
    "\n",
    "# íŒŒì„œ ìƒì„±\n",
    "parser = PydanticOutputParser(pydantic_object=Suggestions)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (íŒŒì„œì˜ í˜•ì‹ ì§€ì‹œì‚¬í•­ í¬í•¨)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"ì£¼ì–´ì§„ ë‹¨ì–´ì— ëŒ€í•œ 3ê°œì˜ ë™ì˜ì–´ë‚˜ ìœ ì‚¬í•œ ë‹¨ì–´ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ë‹¨ì–´: {word}\n",
    "\n",
    "{format_instructions}\"\"\",\n",
    "    input_variables=[\"word\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "print(\"ìƒì„±ëœ í˜•ì‹ ì§€ì‹œì‚¬í•­:\")\n",
    "print(parser.get_format_instructions())\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„±\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "test_words = [\"artificial\", \"intelligent\", \"creative\"]\n",
    "\n",
    "print(f\"\\ní…ŒìŠ¤íŠ¸ ë‹¨ì–´ë“¤: {test_words}\")\n",
    "\n",
    "try:\n",
    "    for word in test_words:\n",
    "        result = chain.invoke({\"word\": word})\n",
    "        print(f\"\\në‹¨ì–´: {word}\")\n",
    "        print(f\"ì œì•ˆëœ ë‹¨ì–´ë“¤: {result.words}\")\n",
    "        print(f\"ê²°ê³¼ íƒ€ì…: {type(result)}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"ê¸°ë³¸ íŒŒì„œ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# ë” ë³µì¡í•œ Pydantic ëª¨ë¸ ì˜ˆì œ\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ë³µí•© Pydantic ëª¨ë¸: ë‹¨ì–´ ë¶„ì„\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "class WordAnalysis(BaseModel):\n",
    "    \"\"\"ë‹¨ì–´ì— ëŒ€í•œ ì¢…í•©ì  ë¶„ì„ ê²°ê³¼\"\"\"\n",
    "    word: str = Field(description=\"ë¶„ì„ ëŒ€ìƒ ë‹¨ì–´\")\n",
    "    definition: str = Field(description=\"ë‹¨ì–´ì˜ ì •ì˜\")\n",
    "    part_of_speech: str = Field(description=\"í’ˆì‚¬ (ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬ ë“±)\")\n",
    "    synonyms: List[str] = Field(description=\"ë™ì˜ì–´ ë¦¬ìŠ¤íŠ¸ (ìµœëŒ€ 3ê°œ)\", max_length=3)\n",
    "    example_sentence: str = Field(description=\"ì‚¬ìš© ì˜ˆì‹œ ë¬¸ì¥\")\n",
    "    difficulty_level: int = Field(description=\"ë‚œì´ë„ (1-10)\", ge=1, le=10)\n",
    "    \n",
    "    @field_validator(\"synonyms\")\n",
    "    @classmethod\n",
    "    def validate_synonyms(cls, synonyms):\n",
    "        \"\"\"ë™ì˜ì–´ ê²€ì¦\"\"\"\n",
    "        if len(synonyms) > 3:\n",
    "            raise ValueError(\"ë™ì˜ì–´ëŠ” ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ í—ˆìš©ë©ë‹ˆë‹¤.\")\n",
    "        return synonyms\n",
    "    \n",
    "    @field_validator(\"part_of_speech\")\n",
    "    @classmethod\n",
    "    def validate_pos(cls, pos):\n",
    "        \"\"\"í’ˆì‚¬ ê²€ì¦\"\"\"\n",
    "        allowed_pos = [\"ëª…ì‚¬\", \"ë™ì‚¬\", \"í˜•ìš©ì‚¬\", \"ë¶€ì‚¬\", \"ì „ì¹˜ì‚¬\", \"ì ‘ì†ì‚¬\", \"ê°íƒ„ì‚¬\"]\n",
    "        if pos not in allowed_pos:\n",
    "            raise ValueError(f\"í—ˆìš©ëœ í’ˆì‚¬ê°€ ì•„ë‹™ë‹ˆë‹¤: {allowed_pos}\")\n",
    "        return pos\n",
    "\n",
    "# ë³µí•© ë¶„ì„ íŒŒì„œ\n",
    "analysis_parser = PydanticOutputParser(pydantic_object=WordAnalysis)\n",
    "\n",
    "# ë³µí•© ë¶„ì„ í”„ë¡¬í”„íŠ¸\n",
    "analysis_prompt = PromptTemplate(\n",
    "    template=\"\"\"ë‹¤ìŒ ë‹¨ì–´ì— ëŒ€í•œ ì¢…í•©ì ì¸ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”:\n",
    "\n",
    "ë‹¨ì–´: {word}\n",
    "\n",
    "ë‹¤ìŒ ì •ë³´ë¥¼ ëª¨ë‘ í¬í•¨í•´ì£¼ì„¸ìš”:\n",
    "- í•œêµ­ì–´ ì •ì˜\n",
    "- í’ˆì‚¬ (ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬, ë¶€ì‚¬, ì „ì¹˜ì‚¬, ì ‘ì†ì‚¬, ê°íƒ„ì‚¬ ì¤‘ í•˜ë‚˜)\n",
    "- ë™ì˜ì–´ 3ê°œ ì´í•˜\n",
    "- ì‚¬ìš© ì˜ˆì‹œ ë¬¸ì¥\n",
    "- ë‚œì´ë„ (1-10)\n",
    "\n",
    "{format_instructions}\"\"\",\n",
    "    input_variables=[\"word\"],\n",
    "    partial_variables={\"format_instructions\": analysis_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# ë³µí•© ë¶„ì„ ì²´ì¸\n",
    "analysis_chain = analysis_prompt | llm | analysis_parser\n",
    "\n",
    "print(\"ë³µí•© ë¶„ì„ í…ŒìŠ¤íŠ¸: 'technology'\")\n",
    "\n",
    "try:\n",
    "    analysis_result = analysis_chain.invoke({\"word\": \"technology\"})\n",
    "    \n",
    "    print(f\"\\n=== ë‹¨ì–´ ë¶„ì„ ê²°ê³¼ ===\")\n",
    "    print(f\"ë‹¨ì–´: {analysis_result.word}\")\n",
    "    print(f\"ì •ì˜: {analysis_result.definition}\")\n",
    "    print(f\"í’ˆì‚¬: {analysis_result.part_of_speech}\")\n",
    "    print(f\"ë™ì˜ì–´: {', '.join(analysis_result.synonyms)}\")\n",
    "    print(f\"ì˜ˆì‹œ ë¬¸ì¥: {analysis_result.example_sentence}\")\n",
    "    print(f\"ë‚œì´ë„: {analysis_result.difficulty_level}/10\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ë³µí•© ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# ì„ íƒì  í•„ë“œê°€ ìˆëŠ” ëª¨ë¸\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ì„ íƒì  í•„ë“œ ëª¨ë¸: ì œí’ˆ ë¦¬ë·° ë¶„ì„\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "class ProductReview(BaseModel):\n",
    "    \"\"\"ì œí’ˆ ë¦¬ë·° ë¶„ì„ ê²°ê³¼\"\"\"\n",
    "    product_name: str = Field(description=\"ì œí’ˆëª…\")\n",
    "    rating: int = Field(description=\"í‰ì  (1-5)\", ge=1, le=5)\n",
    "    sentiment: str = Field(description=\"ê°ì • (ê¸ì •, ë¶€ì •, ì¤‘ë¦½)\")\n",
    "    key_points: List[str] = Field(description=\"ì£¼ìš” í¬ì¸íŠ¸ë“¤\")\n",
    "    recommendation: Optional[str] = Field(None, description=\"ì¶”ì²œ ì—¬ë¶€ (ì„ íƒì‚¬í•­)\")\n",
    "    \n",
    "    @field_validator(\"sentiment\")\n",
    "    @classmethod\n",
    "    def validate_sentiment(cls, sentiment):\n",
    "        allowed_sentiments = [\"ê¸ì •\", \"ë¶€ì •\", \"ì¤‘ë¦½\"]\n",
    "        if sentiment not in allowed_sentiments:\n",
    "            raise ValueError(f\"í—ˆìš©ëœ ê°ì •: {allowed_sentiments}\")\n",
    "        return sentiment\n",
    "\n",
    "# ì œí’ˆ ë¦¬ë·° íŒŒì„œ\n",
    "review_parser = PydanticOutputParser(pydantic_object=ProductReview)\n",
    "\n",
    "# ë¦¬ë·° ë¶„ì„ í”„ë¡¬í”„íŠ¸\n",
    "review_prompt = PromptTemplate(\n",
    "    template=\"\"\"ë‹¤ìŒ ì œí’ˆ ë¦¬ë·°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "ë¦¬ë·° í…ìŠ¤íŠ¸: \"{review_text}\"\n",
    "\n",
    "ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:\n",
    "- ì œí’ˆëª…\n",
    "- í‰ì  (1-5)\n",
    "- ê°ì • (ê¸ì •, ë¶€ì •, ì¤‘ë¦½)\n",
    "- ì£¼ìš” í¬ì¸íŠ¸ë“¤\n",
    "- ì¶”ì²œ ì—¬ë¶€ (ì„ íƒì‚¬í•­)\n",
    "\n",
    "{format_instructions}\"\"\",\n",
    "    input_variables=[\"review_text\"],\n",
    "    partial_variables={\"format_instructions\": review_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# ë¦¬ë·° ë¶„ì„ ì²´ì¸\n",
    "review_chain = review_prompt | llm | review_parser\n",
    "\n",
    "# ìƒ˜í”Œ ë¦¬ë·°\n",
    "sample_review = \"\"\"\n",
    "ì•„ì´í° 15ëŠ” ì •ë§ í›Œë¥­í•œ ìŠ¤ë§ˆíŠ¸í°ì…ë‹ˆë‹¤. \n",
    "ì¹´ë©”ë¼ í’ˆì§ˆì´ ì´ì „ ëª¨ë¸ë³´ë‹¤ í›¨ì”¬ ì¢‹ì•„ì¡Œê³ , \n",
    "ë°°í„°ë¦¬ ìˆ˜ëª…ë„ ë§Œì¡±ìŠ¤ëŸ½ìŠµë‹ˆë‹¤. \n",
    "ë‹¤ë§Œ ê°€ê²©ì´ ì¢€ ë¹„ì‹¸ê¸´ í•˜ì§€ë§Œ ê·¸ë§Œí•œ ê°’ì–´ì¹˜ëŠ” í•˜ëŠ” ê²ƒ ê°™ì•„ìš”.\n",
    "ì „ë°˜ì ìœ¼ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤!\n",
    "\"\"\"\n",
    "\n",
    "print(\"ë¦¬ë·° ë¶„ì„ í…ŒìŠ¤íŠ¸:\")\n",
    "print(f\"ìƒ˜í”Œ ë¦¬ë·°: {sample_review.strip()}\")\n",
    "\n",
    "try:\n",
    "    review_result = review_chain.invoke({\"review_text\": sample_review})\n",
    "    \n",
    "    print(f\"\\n=== ë¦¬ë·° ë¶„ì„ ê²°ê³¼ ===\")\n",
    "    print(f\"ì œí’ˆëª…: {review_result.product_name}\")\n",
    "    print(f\"í‰ì : {review_result.rating}/5\")\n",
    "    print(f\"ê°ì •: {review_result.sentiment}\")\n",
    "    print(f\"ì£¼ìš” í¬ì¸íŠ¸:\")\n",
    "    for i, point in enumerate(review_result.key_points, 1):\n",
    "        print(f\"  {i}. {point}\")\n",
    "    if review_result.recommendation:\n",
    "        print(f\"ì¶”ì²œ: {review_result.recommendation}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ë¦¬ë·° ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def safe_parse_with_retry(chain, input_data, max_retries=3):\n",
    "    \"\"\"íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„í•˜ëŠ” ì•ˆì „í•œ íŒŒì„œ\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            result = chain.invoke(input_data)\n",
    "            print(f\"âœ… ì‹œë„ {attempt + 1}íšŒ ì„±ê³µ\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ì‹œë„ {attempt + 1}íšŒ ì‹¤íŒ¨: {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                print(\"âŒ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨\")\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "# ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\n",
    "print(\"ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸:\")\n",
    "test_result = safe_parse_with_retry(\n",
    "    chain, \n",
    "    {\"word\": \"computer\"}, \n",
    "    max_retries=2\n",
    ")\n",
    "\n",
    "if test_result:\n",
    "    print(f\"ìµœì¢… ê²°ê³¼: {test_result.words}\")\n",
    "\n",
    "# =============================================================================\n",
    "# í™œìš© íŒ ë° ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Pydantic ì¶œë ¥ íŒŒì„œ í™œìš© íŒ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "Pydantic v2 ì£¼ìš” ê°œì„ ì‚¬í•­:\n",
    "1. @field_validator: ë” ëª…í™•í•œ ê²€ì¦ ë¡œì§\n",
    "2. íƒ€ì… íŒíŠ¸ ê°•í™”: ë” ì •í™•í•œ íƒ€ì… ì²´í‚¹\n",
    "3. ì„±ëŠ¥ í–¥ìƒ: ë” ë¹ ë¥¸ ê²€ì¦ ì†ë„\n",
    "4. ì—ëŸ¬ ë©”ì‹œì§€ ê°œì„ : ë” ëª…í™•í•œ ì˜¤ë¥˜ ì •ë³´\n",
    "\n",
    "ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤:\n",
    "1. í•„ë“œ ì„¤ëª… ìƒì„¸íˆ ì‘ì„± (description)\n",
    "2. ì ì ˆí•œ ì œì•½ì¡°ê±´ ì„¤ì • (ge, le, max_length ë“±)\n",
    "3. ì»¤ìŠ¤í…€ ê²€ì¦ ë¡œì§ í™œìš© (@field_validator)\n",
    "4. ì„ íƒì  í•„ë“œ ì ì ˆíˆ í™œìš© (Optional)\n",
    "5. ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§ êµ¬í˜„\n",
    "\n",
    "ì‹¤ì œ í™œìš© ì‚¬ë¡€:\n",
    "- API ì‘ë‹µ êµ¬ì¡°í™”\n",
    "- ë°ì´í„° ì¶”ì¶œ ë° ì •ì œ\n",
    "- ìë™ ê²€ì¦ ë° í’ˆì§ˆ ê´€ë¦¬\n",
    "- êµ¬ì¡°í™”ëœ ë³´ê³ ì„œ ìƒì„±\n",
    "- ë‹¤êµ­ì–´ ë²ˆì—­ ê²°ê³¼ í¬ë§·íŒ…\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nğŸ‰ 7.3.6 Pydantic ì¶œë ¥ íŒŒì„œ ì˜ˆì œ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a2f48d-29c7-40f4-9c1b-8eda403c29ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "my_project_env",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "My Project (Python) (Local)",
   "language": "python",
   "name": "my_project_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
