{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee8e8b97-62ef-4523-bfb1-f2fbe23242ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API í‚¤ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "API í‚¤ ë°œê¸‰: https://platform.openai.com/api-keys\n",
      "âœ… ê¸°ì¡´ í™˜ê²½ ë³€ìˆ˜ì˜ API í‚¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "\n",
      "======================================================================\n",
      "ğŸ¤– LLM ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ\n",
      "\n",
      "======================================================================\n",
      "ğŸ“š í“¨ìƒ· í”„ë¡¬í”„íŠ¸ ì˜ˆì œ 1: ë™ë¬¼ ì„œì‹ì§€ ë¶„ë¥˜\n",
      "======================================================================\n",
      "ğŸ” ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ êµ¬ì¡° í™•ì¸:\n",
      "Identify the habitat of the given animal.\n",
      "(ì£¼ì–´ì§„ ë™ë¬¼ì˜ ì„œì‹ì§€ë¥¼ í™•ì¸í•´ì¤˜.)\n",
      "\n",
      "Animal: lion\n",
      "Habitat: savanna\n",
      "\n",
      "Animal: polar bear\n",
      "Habitat: Arctic ice\n",
      "\n",
      "Animal: elephant\n",
      "Habitat: African grasslands\n",
      "\n",
      "Animal: tiger\n",
      "Habitat:\n",
      "--------------------------------------------------\n",
      "\n",
      "ë°©ë²• 1: RunnableSequence ì‚¬ìš© (LangChain 0.2+ ê¶Œì¥)\n",
      "ğŸ¾ tiger: rainforest or grasslands\n",
      "ğŸ¾ dolphin: ocean\n",
      "ğŸ¾ kangaroo: Australian outback\n",
      "ğŸ¾ penguin: Antarctic ice shelves\n",
      "\n",
      "======================================================================\n",
      "ì°¸ê³ : ê¸°ì¡´ ë°©ì‹ vs ìƒˆë¡œìš´ ë°©ì‹\n",
      "======================================================================\n",
      "\n",
      "# ì´ì „ ë°©ì‹ (Deprecated):\n",
      "from langchain.chains import LLMChain\n",
      "\n",
      "chain = LLMChain(llm=llm, prompt=fewshot_prompt)  # âš ï¸ Deprecated\n",
      "response = chain.run({\"input\": \"tiger\"})          # âš ï¸ Deprecated\n",
      "\n",
      "# ìƒˆë¡œìš´ ë°©ì‹ (ê¶Œì¥):\n",
      "chain = fewshot_prompt | llm                      # âœ… ê¶Œì¥\n",
      "response = chain.invoke({\"input\": \"tiger\"})       # âœ… ê¶Œì¥\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ğŸ“š í“¨ìƒ· í”„ë¡¬í”„íŠ¸ ì˜ˆì œ 2: ê°ì • ë¶„ë¥˜\n",
      "======================================================================\n",
      "ğŸ’­ ê°ì • ë¶„ë¥˜ ê²°ê³¼:\n",
      "'This movie is absolutely amazing!' â†’ positive\n",
      "'I'm disappointed with the quality.' â†’  negative\n",
      "'It's an average product.' â†’ neutral\n",
      "'ì´ ìŒì‹ì´ ì •ë§ ë§›ìˆì–´ìš”!' â†’ positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `_type` key found, defaulting to `prompt`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ì„œë¹„ìŠ¤ê°€ ë³„ë¡œì˜€ìŠµë‹ˆë‹¤.' â†’ negative\n",
      "\n",
      "======================================================================\n",
      "ğŸ’¾ í”„ë¡¬í”„íŠ¸ ì €ì¥ ë° ë¡œë“œ\n",
      "======================================================================\n",
      "âœ… í”„ë¡¬í”„íŠ¸ê°€ 'animal_habitat_prompt.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "âœ… í”„ë¡¬í”„íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ¦ˆ ë¡œë“œëœ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ - shark: ocean\n",
      "\n",
      "======================================================================\n",
      "ğŸ”§ ê³ ê¸‰ í™œìš© íŒ\n",
      "======================================================================\n",
      "\n",
      "1. ì˜ˆì‹œ ê°œìˆ˜ ì œí•œ:\n",
      "   FewShotPromptTemplate(\n",
      "       examples=examples[:2],  # ì²˜ìŒ 2ê°œ ì˜ˆì‹œë§Œ ì‚¬ìš©\n",
      "       max_length=1000,        # ìµœëŒ€ ê¸¸ì´ ì œí•œ\n",
      "       ...\n",
      "   )\n",
      "\n",
      "2. ë™ì  ì˜ˆì‹œ ì„ íƒ:\n",
      "   from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
      "   from langchain.vectorstores import Chroma\n",
      "   from langchain.embeddings import OpenAIEmbeddings\n",
      "   \n",
      "   # ì˜ë¯¸ì  ìœ ì‚¬ì„± ê¸°ë°˜ ì˜ˆì‹œ ì„ íƒê¸°\n",
      "   example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
      "       examples, OpenAIEmbeddings(), Chroma, k=2\n",
      "   )\n",
      "\n",
      "3. ì¡°ê±´ë¶€ ì˜ˆì‹œ:\n",
      "   # ì…ë ¥ì— ë”°ë¼ ë‹¤ë¥¸ ì˜ˆì‹œ ì‚¬ìš©\n",
      "   def select_examples(input_text):\n",
      "       if \"marine\" in input_text.lower():\n",
      "           return marine_examples\n",
      "       else:\n",
      "           return land_examples\n",
      "\n",
      "4. í…œí”Œë¦¿ ì²´ì¸:\n",
      "   # ì—¬ëŸ¬ í“¨ìƒ· í”„ë¡¬í”„íŠ¸ë¥¼ ì—°ê²°\n",
      "   chain1 = prompt1 | llm | output_parser\n",
      "   chain2 = prompt2 | llm\n",
      "   final_chain = chain1 | chain2\n",
      "\n",
      "\n",
      "ğŸ‰ Chapter 7.2 í“¨ìƒ· í”„ë¡¬í”„íŠ¸ ì˜ˆì œ ì™„ë£Œ!\n",
      "ğŸ“š ë‹¤ìŒ ë‹¨ê³„: 7.3ì ˆ LangChainì—ì„œ ì²´ì¸ì´ë€\n"
     ]
    }
   ],
   "source": [
    "# Chapter 7.2 - í“¨ìƒ· í”„ë¡¬í”„íŠ¸ì™€ ì˜ˆì‹œ ì„ íƒê¸° (ìµœì‹  ë²„ì „)\n",
    "# ì›ì„œ ì½”ë“œì˜ LLMChain ë° chain.run() ë©”ì†Œë“œëŠ” deprecated ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "# !pip install langchain==0.2.17 langchain-openai\n",
    "\n",
    "# =============================================================================\n",
    "# API í‚¤ ì„¤ì • (ë…ììš©)\n",
    "# =============================================================================\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "print(\"OpenAI API í‚¤ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "print(\"API í‚¤ ë°œê¸‰: https://platform.openai.com/api-keys\")\n",
    "\n",
    "# API í‚¤ê°€ ì´ë¯¸ í™˜ê²½ ë³€ìˆ˜ì— ìˆëŠ”ì§€ í™•ì¸\n",
    "if 'OPENAI_API_KEY' not in os.environ:\n",
    "    print(\"\\në‹¤ìŒ ì¤‘ í•œ ê°€ì§€ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”:\")\n",
    "    print(\"1. ì•„ë˜ì—ì„œ ì§ì ‘ ì…ë ¥ (ì•ˆì „í•¨ - í™”ë©´ì— í‘œì‹œë˜ì§€ ì•ŠìŒ)\")\n",
    "    print(\"2. í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì • (export OPENAI_API_KEY=your-key)\")\n",
    "    print(\"3. .env íŒŒì¼ ì‚¬ìš©\")\n",
    "    \n",
    "    # ì•ˆì „í•œ ì…ë ¥ ë°©ë²•\n",
    "    try:\n",
    "        api_key = getpass.getpass(\"\\nAPI í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì…ë ¥ ì‹œ í™”ë©´ì— í‘œì‹œë˜ì§€ ì•ŠìŒ): \")\n",
    "        if api_key:\n",
    "            os.environ['OPENAI_API_KEY'] = api_key\n",
    "            print(\"âœ… API í‚¤ê°€ ì•ˆì „í•˜ê²Œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "        else:\n",
    "            print(\"âš ï¸ API í‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nì…ë ¥ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"âœ… ê¸°ì¡´ í™˜ê²½ ë³€ìˆ˜ì˜ API í‚¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# =============================================================================\n",
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ import ë° LLM ì„¤ì •\n",
    "# =============================================================================\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM ì„¤ì •\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "print(\"ğŸ¤– LLM ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "\n",
    "# =============================================================================\n",
    "# í“¨ìƒ· í”„ë¡¬í”„íŠ¸ ì˜ˆì œ 1: ë™ë¬¼ ì„œì‹ì§€ ë¶„ë¥˜\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“š í“¨ìƒ· í”„ë¡¬í”„íŠ¸ ì˜ˆì œ 1: ë™ë¬¼ ì„œì‹ì§€ ë¶„ë¥˜\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ì˜ˆì‹œ ë°ì´í„° (Few-shot examples)\n",
    "examples = [\n",
    "    {\"animal\": \"lion\", \"habitat\": \"savanna\"},\n",
    "    {\"animal\": \"polar bear\", \"habitat\": \"Arctic ice\"},\n",
    "    {\"animal\": \"elephant\", \"habitat\": \"African grasslands\"}\n",
    "]\n",
    "\n",
    "# ê° ì˜ˆì‹œë¥¼ í¬ë§·í•˜ëŠ” í…œí”Œë¦¿\n",
    "example_template = \"\"\"Animal: {animal}\n",
    "Habitat: {habitat}\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"animal\", \"habitat\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "# FewShotPromptTemplate ì •ì˜\n",
    "fewshot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Identify the habitat of the given animal.\\n(ì£¼ì–´ì§„ ë™ë¬¼ì˜ ì„œì‹ì§€ë¥¼ í™•ì¸í•´ì¤˜.)\",\n",
    "    suffix=\"Animal: {input}\\nHabitat:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "print(\"ğŸ” ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ êµ¬ì¡° í™•ì¸:\")\n",
    "sample_formatted = fewshot_prompt.format(input=\"tiger\")\n",
    "print(sample_formatted)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# =============================================================================\n",
    "# ë°©ë²• 1: ìµœì‹  RunnableSequence ë°©ì‹ (ê¶Œì¥)\n",
    "# =============================================================================\n",
    "print(\"\\në°©ë²• 1: RunnableSequence ì‚¬ìš© (LangChain 0.2+ ê¶Œì¥)\")\n",
    "\n",
    "# ìµœì‹  ë°©ì‹: prompt | llm íŒŒì´í”„ë¼ì¸\n",
    "chain = fewshot_prompt | llm\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "test_animals = [\"tiger\", \"dolphin\", \"kangaroo\", \"penguin\"]\n",
    "\n",
    "try:\n",
    "    for animal in test_animals:\n",
    "        response = chain.invoke({\"input\": animal})\n",
    "        print(f\"ğŸ¾ {animal}: {response.content}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    print(\"ğŸ’¡ API í‚¤ê°€ ì •í™•íˆ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "# =============================================================================\n",
    "# ë°©ë²• 2: ê¸°ì¡´ ë°©ì‹ê³¼ ë¹„êµ (ì°¸ê³ ìš©)\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ì°¸ê³ : ê¸°ì¡´ ë°©ì‹ vs ìƒˆë¡œìš´ ë°©ì‹\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "# ì´ì „ ë°©ì‹ (Deprecated):\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=fewshot_prompt)  # âš ï¸ Deprecated\n",
    "response = chain.run({\"input\": \"tiger\"})          # âš ï¸ Deprecated\n",
    "\n",
    "# ìƒˆë¡œìš´ ë°©ì‹ (ê¶Œì¥):\n",
    "chain = fewshot_prompt | llm                      # âœ… ê¶Œì¥\n",
    "response = chain.invoke({\"input\": \"tiger\"})       # âœ… ê¶Œì¥\n",
    "\"\"\")\n",
    "\n",
    "# =============================================================================\n",
    "# í“¨ìƒ· í”„ë¡¬í”„íŠ¸ ì˜ˆì œ 2: ê°ì • ë¶„ë¥˜\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“š í“¨ìƒ· í”„ë¡¬í”„íŠ¸ ì˜ˆì œ 2: ê°ì • ë¶„ë¥˜\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ê°ì • ë¶„ë¥˜ ì˜ˆì‹œ ë°ì´í„°\n",
    "emotion_examples = [\n",
    "    {\"text\": \"I love this new restaurant!\", \"emotion\": \"positive\"},\n",
    "    {\"text\": \"The service was terrible and slow.\", \"emotion\": \"negative\"},\n",
    "    {\"text\": \"The weather is okay today.\", \"emotion\": \"neutral\"}\n",
    "]\n",
    "\n",
    "# ê°ì • ë¶„ë¥˜ìš© ì˜ˆì‹œ í…œí”Œë¦¿\n",
    "emotion_example_template = \"\"\"Text: {text}\n",
    "Emotion: {emotion}\"\"\"\n",
    "\n",
    "emotion_example_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"emotion\"],\n",
    "    template=emotion_example_template\n",
    ")\n",
    "\n",
    "# ê°ì • ë¶„ë¥˜ìš© FewShotPromptTemplate\n",
    "emotion_fewshot_prompt = FewShotPromptTemplate(\n",
    "    examples=emotion_examples,\n",
    "    example_prompt=emotion_example_prompt,\n",
    "    prefix=\"Classify the emotion of the given text as positive, negative, or neutral.\\n(ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ê¸ì •, ë¶€ì •, ì¤‘ë¦½ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.)\",\n",
    "    suffix=\"Text: {input}\\nEmotion:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "# ê°ì • ë¶„ë¥˜ ì²´ì¸\n",
    "emotion_chain = emotion_fewshot_prompt | llm\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤\n",
    "test_sentences = [\n",
    "    \"This movie is absolutely amazing!\",\n",
    "    \"I'm disappointed with the quality.\",\n",
    "    \"It's an average product.\",\n",
    "    \"ì´ ìŒì‹ì´ ì •ë§ ë§›ìˆì–´ìš”!\",\n",
    "    \"ì„œë¹„ìŠ¤ê°€ ë³„ë¡œì˜€ìŠµë‹ˆë‹¤.\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    print(\"ğŸ’­ ê°ì • ë¶„ë¥˜ ê²°ê³¼:\")\n",
    "    for sentence in test_sentences:\n",
    "        result = emotion_chain.invoke({\"input\": sentence})\n",
    "        print(f\"'{sentence}' â†’ {result.content}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ê°ì • ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# í“¨ìƒ· í”„ë¡¬í”„íŠ¸ ì €ì¥ ë° ë¡œë“œ\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ’¾ í”„ë¡¬í”„íŠ¸ ì €ì¥ ë° ë¡œë“œ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "try:\n",
    "    fewshot_prompt.save(\"animal_habitat_prompt.json\")\n",
    "    print(\"âœ… í”„ë¡¬í”„íŠ¸ê°€ 'animal_habitat_prompt.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # ì €ì¥ëœ í”„ë¡¬í”„íŠ¸ ë‹¤ì‹œ ë¡œë“œ\n",
    "    from langchain.prompts import load_prompt\n",
    "    loaded_prompt = load_prompt(\"animal_habitat_prompt.json\")\n",
    "    print(\"âœ… í”„ë¡¬í”„íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # ë¡œë“œëœ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸\n",
    "    loaded_chain = loaded_prompt | llm\n",
    "    test_result = loaded_chain.invoke({\"input\": \"shark\"})\n",
    "    print(f\"ğŸ¦ˆ ë¡œë“œëœ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ - shark: {test_result.content}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ì €ì¥/ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# ê³ ê¸‰ í™œìš©: ë™ì  ì˜ˆì‹œ ì„ íƒ\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”§ ê³ ê¸‰ í™œìš© íŒ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "1. ì˜ˆì‹œ ê°œìˆ˜ ì œí•œ:\n",
    "   FewShotPromptTemplate(\n",
    "       examples=examples[:2],  # ì²˜ìŒ 2ê°œ ì˜ˆì‹œë§Œ ì‚¬ìš©\n",
    "       max_length=1000,        # ìµœëŒ€ ê¸¸ì´ ì œí•œ\n",
    "       ...\n",
    "   )\n",
    "\n",
    "2. ë™ì  ì˜ˆì‹œ ì„ íƒ:\n",
    "   from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "   from langchain.vectorstores import Chroma\n",
    "   from langchain.embeddings import OpenAIEmbeddings\n",
    "   \n",
    "   # ì˜ë¯¸ì  ìœ ì‚¬ì„± ê¸°ë°˜ ì˜ˆì‹œ ì„ íƒê¸°\n",
    "   example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "       examples, OpenAIEmbeddings(), Chroma, k=2\n",
    "   )\n",
    "\n",
    "3. ì¡°ê±´ë¶€ ì˜ˆì‹œ:\n",
    "   # ì…ë ¥ì— ë”°ë¼ ë‹¤ë¥¸ ì˜ˆì‹œ ì‚¬ìš©\n",
    "   def select_examples(input_text):\n",
    "       if \"marine\" in input_text.lower():\n",
    "           return marine_examples\n",
    "       else:\n",
    "           return land_examples\n",
    "\n",
    "4. í…œí”Œë¦¿ ì²´ì¸:\n",
    "   # ì—¬ëŸ¬ í“¨ìƒ· í”„ë¡¬í”„íŠ¸ë¥¼ ì—°ê²°\n",
    "   chain1 = prompt1 | llm | output_parser\n",
    "   chain2 = prompt2 | llm\n",
    "   final_chain = chain1 | chain2\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nğŸ‰ Chapter 7.2 í“¨ìƒ· í”„ë¡¬í”„íŠ¸ ì˜ˆì œ ì™„ë£Œ!\")\n",
    "print(\"ğŸ“š ë‹¤ìŒ ë‹¨ê³„: 7.3ì ˆ LangChainì—ì„œ ì²´ì¸ì´ë€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9dc1cc-a5d7-47ec-bce0-12ff536865f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "my_project_env",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "My Project (Python) (Local)",
   "language": "python",
   "name": "my_project_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
